{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hJ5wX2Dh0la"
      },
      "source": [
        "# VAE\n",
        "\n",
        "Our VAE implementation will consist solely of fully connected layers. We'll take the `1 x 28 x 28` shape of our input and flatten the features to create an input dimension size of 784.\n",
        "\n",
        "In this section you'll define the Encoder and Decoder models, implement the reparametrization trick, forward pass, and loss function to train your first VAE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYVR3yEbdIEg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import argparse\n",
        "import pickle\n",
        "import os\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.nn import init\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# for plotting\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['font.size'] = 16\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxmelEsIcdqU"
      },
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ha8FNIPdUL7"
      },
      "source": [
        "############################################################################################\n",
        "#                                  BEGINNING OF YOUR CODE                                  #\n",
        "############################################################################################\n",
        "# TODO: Check availability of GPU and set the device accordingly                                 #\n",
        "device =\n",
        "############################################################################################\n",
        "#                                  END OF YOUR CODE                                  #\n",
        "############################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKl0wE6ZhyZU"
      },
      "source": [
        "# Downloading the dataset\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "mnist_train = dset.MNIST('./MNIST_data', train=True, download=True,\n",
        "                           transform=T.ToTensor())\n",
        "loader_train = DataLoader(mnist_train, batch_size=batch_size,\n",
        "                          shuffle=True, drop_last=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz2h0lcXy03J"
      },
      "source": [
        "# Custom Function to show images\n",
        "\n",
        "def show_images(images):\n",
        "    images = torch.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
        "    sqrtn = int(math.ceil(math.sqrt(images.shape[0])))\n",
        "    sqrtimg = int(math.ceil(math.sqrt(images.shape[1])))\n",
        "\n",
        "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
        "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBQngPeQjLuM"
      },
      "source": [
        "## Define the model parameters\n",
        "\n",
        "1. Define the `encoder`, `decoder`, `mu_layer`, and `logvar_layer` in the initialization (`__init__` function) of the below class. Use nn.Sequential to define the encoder, and separate Linear layers for the mu and logvar layers. In all of these layers, H will be a hidden dimension you set and will be the same across all encoder and decoder layers.\n",
        "\n",
        "**Architecture for the encoder is described below:**\n",
        "\n",
        "\n",
        " * `Flatten` (Hint: nn.Flatten)\n",
        " * Fully connected layer with input size 784 (`input_size`) and output size H\n",
        " * `LeakyReLU` with negative slope of 0.01\n",
        " * Fully connected layer with input_size H and output size H\n",
        " * `LeakyReLU` with negative slope of 0.01\n",
        "\n",
        "We'll now define the decoder, which will take the latent space representation and generate a reconstructed image. The architecture is as follows:\n",
        "\n",
        "\n",
        " **Architecture for the decoder is described below:**\n",
        "\n",
        "\n",
        " * Fully connected layer with input size as the latent size (Z) and output size H\n",
        " * `LeakyReLU` with negative slope of 0.01\n",
        " * Fully connected layer with input_size H and output size H\n",
        " * `LeakyReLU` with negative slope of 0.01\n",
        " * Fully connected layer with input_size H and output size H\n",
        " * `LeakyReLU` with negative slope of 0.01\n",
        " * Fully connected layer with input_size H and output size H\n",
        " * `LeakyReLU` with negative slope of 0.01\n",
        " * Fully connected layer with input_size H and output size 784 (`input_size`)\n",
        " * `Sigmoid`\n",
        " * `Unflatten` (nn.Unflatten)\n",
        "\n",
        "\n",
        "Please do not touch the `forward` function for now. We will come back to it later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqsz8iHCi03O"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_size, latent_size=15):\n",
        "        super(VAE, self).__init__()\n",
        "        self.input_size = input_size # H*W\n",
        "        self.latent_size = latent_size # Z\n",
        "        self.hidden_dim = 150\n",
        "\n",
        "        self.encoder = None\n",
        "        self.mu_layer = None\n",
        "        self.logvar_layer = None\n",
        "        self.decoder = None\n",
        "\n",
        "        ############################################################################################\n",
        "        #                                  BEGINNING OF YOUR CODE                                  #\n",
        "        ############################################################################################\n",
        "        ############################################################################################\n",
        "        # TODO: Implement the fully-connected encoder architecture described in the notebook.      #\n",
        "        # Specifically, self.encoder should be a network that inputs a batch of input images of    #\n",
        "        # shape (N, 1, H, W) into a batch of hidden features of shape (N, H_d). Set up             #\n",
        "        # self.mu_layer and self.logvar_layer to be a pair of linear layers that map the hidden    #\n",
        "        # features into estimates of the mean and log-variance of the posterior over the latent    #\n",
        "        # vectors; the mean and log-variance estimates will both be tensors of shape (N, Z).       #\n",
        "        ############################################################################################\n",
        "\n",
        "\n",
        "        # Define the encoder: A two Linear+ReLU layers neural network.\n",
        "        self.encoder =\n",
        "\n",
        "        # Define the mu_layer, with input (N, H_d) and output (N, Z)\n",
        "        self.mu_layer =\n",
        "        # Define the logvar_layer, with input (N, H_d) and output (N, Z)\n",
        "        self.logvar_layer =\n",
        "\n",
        "        ############################################################################################\n",
        "        # TODO: Implement the fully-connected decoder architecture described in the notebook.      #\n",
        "        # Specifically, self.decoder should be a network that inputs a batch of latent vectors of  #\n",
        "        # shape (N, Z) and outputs a tensor of estimated images of shape (N, 1, H, W).             #\n",
        "        ############################################################################################\n",
        "\n",
        "\n",
        "        self.decoder =\n",
        "\n",
        "        ############################################################################################\n",
        "        #                                      END OF YOUR CODE                                    #\n",
        "        ############################################################################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Performs forward pass through FC-VAE model by passing image through\n",
        "        encoder, reparametrize trick, and decoder models\n",
        "\n",
        "        Inputs:\n",
        "        - x: Batch of input images of shape (N, 1, H, W)\n",
        "\n",
        "        Returns:\n",
        "        - x_hat: Reconstruced input data of shape (N,1,H,W)\n",
        "        - mu: Matrix representing estimated posterior mu (N, Z), with Z latent space dimension\n",
        "        - logvar: Matrix representing estimataed variance in log-space (N, Z), with Z latent space dimension\n",
        "        \"\"\"\n",
        "        x_hat = None\n",
        "        mu = None\n",
        "        logvar = None\n",
        "\n",
        "        ############################################################################################\n",
        "        #                                  BEGINNING OF YOUR CODE                                  #\n",
        "        ############################################################################################\n",
        "        ############################################################################################\n",
        "        # TODO: Implement the forward pass by following these steps                                #\n",
        "        # (1) Pass the input batch through the encoder model, pass the output to mu_layer and      #\n",
        "        # logvar_layer to get the posterior mu and logvariance                                     #\n",
        "        # (2) Reparametrize to compute  the latent vector z                                        #\n",
        "        # (3) Pass z through the decoder to resconstruct x                                         #\n",
        "        ############################################################################################\n",
        "\n",
        "        # Pass input images \"x\" to the encoder. Output shape is: (N, H_d)\n",
        "        encoder_out =\n",
        "\n",
        "        # Get the posterior mu from the encoder's output. Its shape is: (N, Z)\n",
        "        mu =\n",
        "        # Get the posterior logvariance from the encoder's output. Its shape is: (N, Z)\n",
        "        logvar =\n",
        "\n",
        "        # Reparametrize to compute the latent vector \"z\", of shape (N, Z)\n",
        "        z =\n",
        "\n",
        "        # Pass \"z\" through the decoder to resconstruct \"x\", the \"x_hat\".\n",
        "        x_hat =\n",
        "\n",
        "        ############################################################################################\n",
        "        #                                      END OF YOUR CODE                                    #\n",
        "        ############################################################################################\n",
        "        return x_hat, mu, logvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzNMeW1Ym2F2"
      },
      "source": [
        "## Reparameterization Trick\n",
        "\n",
        "Now we'll apply a reparametrization trick in order to estimate the posterior $z$ during our forward pass, given the $\\mu$ and $\\sigma^2$ estimated by the encoder. A simple way to do this could be to simply generate a normal distribution centered at our  $\\mu$ and having a std corresponding to our $\\sigma^2$. However, we would have to backpropogate through this random sampling that is not differentiable. Instead, we sample initial random data $\\epsilon$ from a fixed distrubtion, and compute $z$ as a function of ($\\epsilon$, $\\sigma^2$, $\\mu$). Specifically:\n",
        "\n",
        "$z = \\mu + \\sigma\\epsilon$\n",
        "\n",
        "We can easily find the partial derivatives w.r.t $\\mu$ and $\\sigma^2$ and backpropagate through $z$. If $\\epsilon = \\mathcal{N} (0,1)$, then its easy to verify that the result of our forward pass calculation will be a distribution centered at $\\mu$ with variance $\\sigma^2$.\n",
        "\n",
        "Implement the `reparametrization` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C_bFtNejgbr"
      },
      "source": [
        "def reparametrize(mu, logvar):\n",
        "    \"\"\"\n",
        "    Differentiably sample random Gaussian data with specified mean and variance using the\n",
        "    reparameterization trick.\n",
        "    Inputs:\n",
        "    - mu: Tensor of shape (N, Z) giving means\n",
        "    - logvar: Tensor of shape (N, Z) giving log-variances\n",
        "    Returns:\n",
        "    - z: Estimated latent vector of shape (N, Z), where z[i, j] is a random value sampled from a Gaussian with\n",
        "         mean mu[i, j] and log-variance logvar[i, j].\n",
        "    \"\"\"\n",
        "    z = None\n",
        "\n",
        "    ################################################################################################\n",
        "    #                                  BEGINNING OF YOUR CODE                                      #\n",
        "    ################################################################################################\n",
        "    ################################################################################################\n",
        "    # TODO: Reparametrize by initializing epsilon as a normal distribution and scaling by          #\n",
        "    # posterior mu and sigma to estimate z                                                         #\n",
        "    ################################################################################################\n",
        "\n",
        "\n",
        "    # Convert the \"log of the variance\" to \"sigma\" (standard deviation).\n",
        "    sigma =\n",
        "\n",
        "    # Compute 'z'.\n",
        "    # Epsilon is a Tensor that contains random samples from a standard normal\n",
        "    # distribution (mu=0, std=1)\n",
        "    z =\n",
        "\n",
        "    ################################################################################################\n",
        "    #                              END OF YOUR CODE                                                #\n",
        "    ################################################################################################\n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3RBCZL6nFWf"
      },
      "source": [
        "## Define the forward pass in the `VAE` class\n",
        "\n",
        "Go back to the cell above the Reparameterization trick header, which contains the definition of the `VAE` class.\n",
        "\n",
        "Implement the forward pass in the `forward` function, and run the cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyMgNxsRnfH_"
      },
      "source": [
        "## Loss function\n",
        "\n",
        "The loss function for VAEs contains two terms: A reconstruction loss term (left) and KL divergence term (right).\n",
        "\n",
        "$-E_{Z~q_{\\phi}(z|x)}[log p_{\\theta}(x|z)] + D_{KL}(q_{\\phi}(z|x), p(z)))$\n",
        "\n",
        "Note that this is the negative of the variational lowerbound -this ensures that when we are minimizing this loss term, we're maximizing the variational lowerbound. The reconstruction loss term can be computed by simply using the binary cross entropy loss between the original input pixels and the output pixels of our decoder (Hint: `nn.functional.binary_cross_entropy`). The KL divergence term works to force the latent space distribution to be close to a prior distribution (we're using a standard normal gaussian as our prior).\n",
        "\n",
        "To help you out, we've derived an unvectorized form of the KL divergence term for you.\n",
        "Suppose that $q_\\phi(z|x)$ is a $Z$-dimensional diagonal Gaussian with mean $\\mu_{z|x}$ of shape $(Z,)$ and standard deviation $\\sigma_{z|x}$ of shape $(Z,)$, and that $p(z)$ is a $Z$-dimensional Gaussian with zero mean and unit variance. Then we can write the KL divergence term as:\n",
        "\n",
        "$D_{KL}(q_{\\phi}(z|x), p(z))) = -\\frac{1}{2} \\sum_{j=1}^{J} (1 + log(\\sigma_{z|x}^2)_{j} - (\\mu_{z|x})^2_{j} - (\\sigma_{z|x})^2_{j}$)\n",
        "\n",
        "Implement a vectorized version of this loss that operates on minibatches.\n",
        "You should average the loss across samples in the minibatch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiWEliJll3KM"
      },
      "source": [
        "def loss_function(x_hat, x, mu, logvar):\n",
        "    \"\"\"\n",
        "    Computes the negative variational lower bound loss term of the VAE (refer to formulation in notebook).\n",
        "    Inputs:\n",
        "    - x_hat: Reconstruced input data of shape (N, 1, H, W)\n",
        "    - x: Input data for this timestep of shape (N, 1, H, W)\n",
        "    - mu: Matrix representing estimated posterior mu (N, Z), with Z latent space dimension\n",
        "    - logvar: Matrix representing estimated variance in log-space (N, Z), with Z latent space dimension\n",
        "\n",
        "    Returns:\n",
        "    - loss: Tensor containing the scalar loss for the negative variational lowerbound\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "\n",
        "    ################################################################################################\n",
        "    #                                  BEGINNING OF YOUR CODE                                      #\n",
        "    ################################################################################################\n",
        "    ################################################################################################\n",
        "    # TODO: Compute negative variational lowerbound loss as described in the notebook.             #\n",
        "    # Note that the log variance is provided as the input to your function. Interpret the hints    #\n",
        "    # above accordingly.\n",
        "    ################################################################################################\n",
        "\n",
        "\n",
        "    # Get the minibatch size\n",
        "    N =\n",
        "\n",
        "    # Compute the reconstruction loss term, using Binary Cross Entropy (BCE) loss.\n",
        "    # The \"BCE loss\" have to be adapted to the \"reconstruction loss\" (Expectation) by:\n",
        "    # - Changing the reduction mode from 'mean' (default) to 'sum' (used in the Expectation).\n",
        "    # - The input to the BCE is 'x_hat' and the target is 'x'. This can be done because we are\n",
        "    # operating on MNIST dataset, where each pixel is either 0 or 1.\n",
        "    # Note that the minus sign is handled by the BCE loss itself.\n",
        "    rec_term =\n",
        "\n",
        "    # Compute the KL divergence term (kldiv_term).\n",
        "    kldiv_term =\n",
        "    kldiv_term =\n",
        "\n",
        "    # Final loss is the sum of \"reconstruction loss term\" and \"KL divergence term\".\n",
        "    loss =\n",
        "\n",
        "    # Average the loss across samples in the minibatch.\n",
        "    loss =\n",
        "\n",
        "    ################################################################################################\n",
        "    #                            END OF YOUR CODE                                                  #\n",
        "    ################################################################################################\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2NahGjLwTWW"
      },
      "source": [
        "## Train the VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h0Qt5jVwr4L"
      },
      "source": [
        "# Leave this cell untouched\n",
        "def train_vae(epoch, model, train_loader):\n",
        "    \"\"\"\n",
        "    Train the VAE!\n",
        "\n",
        "    Inputs:\n",
        "    - epoch: Current epoch number\n",
        "    - model: VAE model object\n",
        "    - train_loader: PyTorch Dataloader object that contains our training data\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    num_classes = 10\n",
        "    loss = None\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.data\n",
        "        optimizer.step()\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
        "        epoch, loss.data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slirT1GSwUXE"
      },
      "source": [
        "# Leave this cell untouched\n",
        "\n",
        "set_seed(0)\n",
        "\n",
        "num_epochs = 10\n",
        "latent_size = 15\n",
        "input_size = 28*28\n",
        "\n",
        "\n",
        "vae_model = VAE(input_size, latent_size=latent_size)\n",
        "vae_model.to(device)\n",
        "for epoch in range(0, num_epochs):\n",
        "  train_vae(epoch, vae_model, loader_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhUx6MbPzXo-"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "Report the final training loss displayed after training the VAE, as displayed in the cell.(Select the closest answer)\n",
        "\n",
        "1. 116\n",
        "2. 103\n",
        "3. 128\n",
        "4. 90"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRU6mPsa3C05"
      },
      "source": [
        "# Adversarial Autoencoder(AAE)\n",
        "\n",
        "In the following problem we will implement an Adversarial Autoencoder(AAE) to map MNIST images into latent representations that follow a Gaussian distribution. Please refer to the lecture to understand the idea behind AAE.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY0BKYT13y8-"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04BBosbH-ysQ"
      },
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjNw0exp4RAu"
      },
      "source": [
        "def show_images(images):\n",
        "    images = torch.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
        "    sqrtn = int(math.ceil(math.sqrt(images.shape[0])))\n",
        "    sqrtimg = int(math.ceil(math.sqrt(images.shape[1])))\n",
        "\n",
        "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
        "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKCzWX2u36_5"
      },
      "source": [
        "dtype = torch.float\n",
        "\n",
        "# set device\n",
        "\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIlAsdo74Dzm"
      },
      "source": [
        "# let us load the input images from the dataset and visualize some images!\n",
        "\n",
        "batch_size = 128\n",
        "NOISE_DIM = 96\n",
        "\n",
        "print('download MNIST if not exist')\n",
        "\n",
        "mnist_train = dset.MNIST('./MNIST_data', train=True, download=True,\n",
        "                           transform=T.ToTensor())\n",
        "loader_train = DataLoader(mnist_train, batch_size=batch_size,\n",
        "                          shuffle=True, drop_last=True, num_workers=2)\n",
        "\n",
        "\n",
        "imgs = loader_train.__iter__().next()[0].view(batch_size, 784)\n",
        "show_images(imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdjcIjLD4fhC"
      },
      "source": [
        "## Generating Random Noise\n",
        "\n",
        "The first step is to generate gaussian noise with mean 0 and variance 25 with shape `[batch_size, noise_dim]`. This noise will be used to draw samples of  vectors with the desired prior distribution to which we want to map our latent representations.\n",
        "\n",
        "Hint: use `torch.randn`.\n",
        "\n",
        "Implement `sample_gaussian_noise` below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEhLLyOZOExi"
      },
      "source": [
        "def sample_gaussian_noise(batch_size, noise_dim, dtype=torch.float, device='cpu'):\n",
        "  \"\"\"\n",
        "  Generate a PyTorch Tensor of uniform random noise.\n",
        "\n",
        "  Input:\n",
        "  - batch_size: Integer giving the batch size of noise to generate.\n",
        "  - noise_dim: Integer giving the dimension of noise to generate.\n",
        "\n",
        "  Output:\n",
        "  - A PyTorch Tensor of shape (batch_size, noise_dim) containing gaussian noise with mean 0 and variance 25.\n",
        "  \"\"\"\n",
        "  noise = None\n",
        "  ##############################################################################\n",
        "  #                           BEGINNING OF YOUR CODE                           #\n",
        "  ##############################################################################\n",
        "  ##############################################################################\n",
        "  # TODO: Implement sample_noise.                                              #\n",
        "  ##############################################################################\n",
        "\n",
        "  # The generated noise values (from gaussian distribution) must have mean 0\n",
        "  # and variance 25.\n",
        "  # However, \"torch.randn\" generates noise with variance 1.\n",
        "  # For that, we must multiply the noise with appropiate constant which is the\n",
        "  # square root of the desired variance.\n",
        "\n",
        "  noise =\n",
        "\n",
        "  ##############################################################################\n",
        "  #                              END OF YOUR CODE                              #\n",
        "  ##############################################################################\n",
        "\n",
        "  return noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWvV_e6b5Aa_"
      },
      "source": [
        "## Encoder, Decoder and Discriminator\n",
        "\n",
        "**The definitions of these functions are provided to you.**\n",
        "\n",
        "They are explained below:\n",
        "\n",
        "### Encoder\n",
        "\n",
        "The architecture is:\n",
        " * Fully connected layer with input size 784 and output size 256\n",
        " * `LeakyReLU with alpha 0.01`\n",
        " * Fully connected layer with input size 256 and output size 256\n",
        " * `LeakyReLU with alpha 0.01`\n",
        " * Fully connected layer with input size 256 and output size is the `latent_size`.\n",
        "  \n",
        "The output of the discriminator is of shape `[batch_size, latent size]`, and contains the latent representations of each of the `batch_size` inputs.\n",
        "\n",
        "### Decoder\n",
        "\n",
        "The architecture is:\n",
        " * Fully connected layer from `latent_size` to 1024\n",
        " * `ReLU`\n",
        " * Fully connected layer with input size 1024 and output size 1024\n",
        " * `ReLU`\n",
        " * Fully connected layer with input size 1024 and output size 784\n",
        " * `Sigmoid` (to clip the image to be in the range of [0,1])\n",
        "\n",
        " This outputs a tensor of shape of `[batch_size, 784]` that is the   reconstructed images in the batch.\n",
        "\n",
        "### Discriminator\n",
        "\n",
        "The architecture is:\n",
        " * Fully connected layer from `latent_size` to 256\n",
        " * `LeakyReLU with alpha 0.01`\n",
        " * Fully connected layer with input size 256 and output size 256\n",
        " * `LeakyReLU with alpha 0.01`\n",
        " * Fully connected layer with input size 256 and output size 1\n",
        "\n",
        " This outputs a tensor of shape of `[batch_size, 1]` that is indication whether the latent noise input is coming for the real prior distribuition or not."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LATENT_SIZE = 24 # default noise dimension\n",
        "\n",
        "##############################################################################\n",
        "#                           BEGINNING OF YOUR CODE                           #\n",
        "##############################################################################\n",
        "##############################################################################\n",
        "\n",
        "def encoder(latent_size=LATENT_SIZE):\n",
        "  ##############################################################################\n",
        "  #TODO: Build and return a PyTorch nn.Sequential model implementing the architecture in the notebook.\n",
        "  ##############################################################################\n",
        "\n",
        "  model =\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def decoder(latent_size=LATENT_SIZE):\n",
        "  ##############################################################################\n",
        "  #TODO: Build and return a PyTorch nn.Sequential model implementing the\n",
        "  # architecture in the notebook.\n",
        "  ##############################################################################\n",
        "  model =\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def discriminator(latent_size=LATENT_SIZE):\n",
        "  ##############################################################################\n",
        "  #TODO: Build and return a PyTorch nn.Sequential model implementing the\n",
        "  # architecture in the notebook.\n",
        "  ##############################################################################\n",
        "  model =\n",
        "\n",
        "  return model\n",
        "\n",
        "##############################################################################\n",
        "#                              END OF YOUR CODE                              #\n",
        "##############################################################################"
      ],
      "metadata": {
        "id": "-FcOfIwcS4CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkYTW6UF5oKQ"
      },
      "source": [
        "## Loss functions\n",
        "\n",
        "We will compute the generator and discriminator loss.\n",
        "\n",
        "The generator loss is:\n",
        "$$\\ell_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
        "and the discriminator loss is:\n",
        "$$ \\ell_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
        "We will be *minimizing* these losses. We have already implemented the functions to compute these losses. Please go trhough them carefully.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Jjl_Me5pnf"
      },
      "source": [
        "def discriminator_loss(logits_real, logits_fake):\n",
        "  \"\"\"\n",
        "  Computes the discriminator loss described above.\n",
        "\n",
        "  Inputs:\n",
        "  - logits_real: PyTorch Tensor of shape (N,) giving scores for the real data.\n",
        "  - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
        "\n",
        "  Returns:\n",
        "  - loss: PyTorch Tensor containing (scalar) the loss for the discriminator.\n",
        "  \"\"\"\n",
        "  loss = None\n",
        "\n",
        "  # For the discriminator (D), the true target (y = 1) corresponds to \"real\" vectors.\n",
        "  # Thus, for the scores of real vectors, the target is always 1 (a vector).\n",
        "  real_labels = torch.ones_like(logits_real, device=device)\n",
        "  # Compute the BCE for the scores of the real vectors.\n",
        "  # Note that the BCE itself uses the Expectation formula (in addition, an average is\n",
        "  # taken throughout the losses, not a sum [as requested in this assignment]).\n",
        "  real_loss = F.binary_cross_entropy_with_logits(logits_real, real_labels)\n",
        "\n",
        "  # For D, the false target (y = 0) corresponds to \"fake\" vectors.\n",
        "  # Thus, for the scores of fake vectors, the target is always 0 (a vector).\n",
        "  fake_labels = torch.zeros_like(logits_fake, device=device)\n",
        "  # As for the real scores, compute the BCE loss for the fake vectors.\n",
        "  fake_loss = F.binary_cross_entropy_with_logits(logits_fake, fake_labels)\n",
        "\n",
        "  # Sum \"real\" and \"fake\" losses.\n",
        "  # That is, BCE has already taken into account the \"negated equation\" form,\n",
        "  # the \"log\" (in the Expectation) and the \"mean\" (insetead on the \"sum\").\n",
        "  loss = real_loss + fake_loss\n",
        "\n",
        "  return loss\n",
        "\n",
        "def generator_loss(logits_fake):\n",
        "  \"\"\"\n",
        "  Computes the generator loss described above.\n",
        "\n",
        "  Inputs:\n",
        "  - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
        "\n",
        "  Returns:\n",
        "  - loss: PyTorch Tensor containing the (scalar) loss for the generator.\n",
        "  \"\"\"\n",
        "  loss = None\n",
        "\n",
        "  # For the generator (G), the true target (y = 1) corresponds to \"fake\" vectors.\n",
        "  # Thus, for the scores of fake vectors, the target is always 1 (a vector).\n",
        "  fake_labels = torch.ones_like(logits_fake, device=device)\n",
        "  # Compute the BCE for the scores of the fake vectors.\n",
        "  fake_loss = F.binary_cross_entropy_with_logits(logits_fake, fake_labels)\n",
        "\n",
        "  # The generator loss is \"fake_loss\".\n",
        "  # That is, BCE has already taken into account the \"negated equation\" form,\n",
        "  # the \"log\" (in the Expectation) and the \"mean\" (insetead on the \"sum\").\n",
        "  loss = fake_loss\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3zkv8Mp69Kx"
      },
      "source": [
        "## Training\n",
        "\n",
        "Complete the code below for the main training loop of the Adverserial Autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_aae(En, De, Ds, En_solver, De_solver, Ds_solver, Gn_solver, show_every=250,\n",
        "              batch_size=128, latent_size=LATENT_SIZE, num_epochs=5):\n",
        "  \"\"\"\n",
        "  Train an AAA!\n",
        "\n",
        "  Inputs:\n",
        "  - En, De, Ds: PyTorch models for the encoder, decoder and discriminator\n",
        "  - En_solver, De_solver, Ds_solver, Gn_solver: torch.optim Optimizers to use for training the\n",
        "    Enoder, Decoder, Discriminator and Generator(ie the encoder when it is used as a generator).\n",
        "  - show_every: Show samples after every show_every iterations.\n",
        "  - batch_size: Batch size to use for training.\n",
        "  - latent_size: Dimension of the latent representation of the inputs.\n",
        "  - num_epochs: Number of epochs over the training dataset to use for training.\n",
        "  \"\"\"\n",
        "  iter_count = 0\n",
        "  for epoch in range(num_epochs):\n",
        "    for x, _ in loader_train:\n",
        "      if len(x) != batch_size:\n",
        "        continue\n",
        "\n",
        "      ##############################################################################\n",
        "      #                           BEGINNING OF YOUR CODE                           #\n",
        "      ##############################################################################\n",
        "      ##############################################################################\n",
        "\n",
        "      En_solver.zero_grad()\n",
        "      De_solver.zero_grad()\n",
        "      real_data = x.view(-1, 784).to(device)\n",
        "\n",
        "      ##############################################################################\n",
        "      #TODO: Compute the latent representations and the reconstructed images using\n",
        "      # the encoder, deocder\n",
        "      ##############################################################################\n",
        "\n",
        "      latent_sample =\n",
        "      recon_data =\n",
        "\n",
        "      ##############################################################################\n",
        "      #TODO: Compute the reconstruction loss between the real data and the\n",
        "      # reconsructed data using binary cross entropy with reduction as 'sum'\n",
        "      ##############################################################################\n",
        "\n",
        "      recon_loss =\n",
        "\n",
        "      ##############################################################################\n",
        "      #TODO: Backpropagate the recon_loss and do an optimization step on the encoder\n",
        "      # and decoder solvers\n",
        "      ##############################################################################\n",
        "\n",
        "\n",
        "\n",
        "      En.eval()\n",
        "\n",
        "      ##############################################################################\n",
        "      # Generating random latent samples with desired gaussian distribution\n",
        "      ##############################################################################\n",
        "      real_latent =\n",
        "\n",
        "      ##############################################################################\n",
        "      #TODO: Generate fake latent samples from the real data using the encoder\n",
        "      ##############################################################################\n",
        "      fake_latent =\n",
        "\n",
        "      ##############################################################################\n",
        "      #TODO: Compute the logits corresponding to the real latent vectors and the fake\n",
        "      # latent vectors using the discriminator\n",
        "      ##############################################################################\n",
        "      logits_real_latent =\n",
        "      logits_fake_latent =\n",
        "\n",
        "      ##############################################################################\n",
        "      #TODO: Compute the discriminator loss between the logits corresponding to the\n",
        "      # real and fake latents using the discriminator loss function defined before\n",
        "      ##############################################################################\n",
        "\n",
        "      ds_total_loss =\n",
        "      ##############################################################################\n",
        "      #TODO: Backpropagate the discriminator loss and do an optimization step on the\n",
        "      # discriminator solver\n",
        "      ##############################################################################\n",
        "\n",
        "\n",
        "\n",
        "      ##############################################################################\n",
        "      #                              END OF YOUR CODE                              #\n",
        "      ##############################################################################\n",
        "\n",
        "      En.train()\n",
        "\n",
        "      ##############################################################################\n",
        "      # Training the encoder based on the generator loss\n",
        "      ##############################################################################\n",
        "\n",
        "      latent_sample_fake = En(real_data)\n",
        "      gen_logits_fake = Ds(latent_sample_fake)\n",
        "      g_loss = generator_loss(gen_logits_fake)\n",
        "\n",
        "      g_loss.backward()\n",
        "      Gn_solver.step()\n",
        "\n",
        "      if (iter_count % show_every == 0):\n",
        "        print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count,ds_total_loss.item(),g_loss.item()))\n",
        "        imgs_numpy = recon_data.data.cpu()#.numpy()\n",
        "        show_images(imgs_numpy[0:16])\n",
        "        plt.show()\n",
        "        print()\n",
        "      iter_count += 1\n",
        "    if epoch == num_epochs - 1:\n",
        "      show_images(imgs_numpy[0:16])\n"
      ],
      "metadata": {
        "id": "irphg16RYS3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo1ajReC7NA-"
      },
      "source": [
        "Now run the cell below to train the Adverserial Autoencoder!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leave this cell untouched\n",
        "\n",
        "set_seed(0)\n",
        "\n",
        "# Make the discriminator\n",
        "En = encoder().to(device)\n",
        "\n",
        "# Make the discriminator\n",
        "De = decoder().to(device)\n",
        "\n",
        "# Make the generator\n",
        "Ds = discriminator().to(device)\n",
        "\n",
        "# Use the function you wrote earlier to get optimizers for the Discriminator and the Generator\n",
        "En_solver = optim.Adam(En.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
        "De_solver = optim.Adam(De.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
        "Ds_solver = optim.Adam(Ds.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
        "Gn_solver = optim.Adam(En.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
        "\n",
        "# Run it!\n",
        "run_aae(En, De, Ds, En_solver, De_solver, Ds_solver, Gn_solver)"
      ],
      "metadata": {
        "id": "3VW2_Xjom2Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4K6u9Qu1IjD"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "What is the discriminator error after 2250 iterations displayed in the cell?\n",
        "\n",
        "1. 0-10\n",
        "2. 11-20\n",
        "3. 21-30\n",
        "4. 31-40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O72WWjjQ7gMP"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "What is the generator error after 2250 iterations displayed in the cell?\n",
        "\n",
        "1. 0.5-0.99\n",
        "2. 1-1.99\n",
        "3. 3-3.99\n",
        "4. 2-2.99\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nlOVCCG0zqhd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}